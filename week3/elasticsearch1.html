<!DOCTYPE html><html lang=en><head>
  <meta http-equiv=Content-Type content="text/html; charset=UTF-8"><meta name=viewport content="width=device-width,initial-scale=1"><link rel="stylesheet" href="../css/slidestyles.css" type="text/css" media="screen" charset="utf-8">
    <title>Elasticsearch Day 1</title>

</head>

<!-- #ToDo: Change 16:9 to 4:3 or vice versa, according to the current projector / screen -->
<body onload="var slideshow = remark.create({ratio: '16:9', navigation: {scroll: true, touch: true, click: false}, countIncrementalSlides: false, highlightLanguage: 'bash', highlightStyle: 'tomorrow-night-blue'});">

<!-- #ToDo: Write your slides in MarkDown here -->

<textarea id="source">


class: center, middle

# Elasticsearch

## Introduction

---
# ES Use cases

* Advanced search
  * Full-text search
  * Online stores (e.g. "suggested for you" features)
  * Distance calculations

--

* Analytics - for very large datasets

--

* NOT for primary datastore (data loss/corruption)

---

# Databases (So Far)

* SQL Relational Database

--

* MySQL, PostgreSQL, SQLite

--

* Defined schema

--

* Allows you to set restrictions, run JOINs, avoid consistency issues

![table1](images/table1.png)

---

# Databases… NoSQL

* Non-Relational Database

--

* MongoDB, CouchDB, Redis, Apache Cassandra

--

* Flexible, dynamic table design

--

* Fast, can be distributed  

![snippet](images/snippet.png)
---

# JSON

<div class = "left-column" >

<ul>
	<li>JavaScript Object Notation
	<li>Data is text
	<li>Converts to a JS object simply, quickly, no parsing
	<li>Key:Value pairs make it easy to understand

</div>
<div class = "right-column">

<img style = "transform: scale(2.2)" src = "images/JSONexample.png">

</div>
---

# Lucene

Elasticsearch is built on Lucene, a search library written in Java.

* Stores data in an **index** of documents
  * Each **document** has **fields**
  * For now, think of an index as the analog of a database in a RDBMS

--

* Inverted indexes - like in back of textbook (faster to search, slower to write)

--

* Allows fields to be weighted using the `boost` parameter

--

* Boolean queries (and, or, not)

--

* Lucene Query Syntax

---

# Nodes, Clusters & Shards, Oh My!

* A **node** is a single server, participating in the ES cluster.

--

* A **cluster** is a group of 1+ servers, who index/search together.

--

* A **shard** is a bucket of data. This allows one index to be split among multiple nodes in one cluster. A node one or more shards.

--

* ES will manage finding data in the various shards via a **master node** when there are 2+ nodes in your cluster.
	
---

## Clusters

<img src="images/clusterdiagram.png" style="height:500px !important;" />

---

# Fault Tolerance

* "health" and failure tolerance

--

* Replicas distributed on different nodes in case of failures

--

* Master node figures out which node has your data

--

* Scale out — searches can be executed on replicas in parallel

---

# Let Someone Else Manage It

Elasticsearch clusters are often set up on services such as:

* AWS Hosted ES Service
* Heroku's Bonsai service
* Searchly (IBM)

---

# ES Alternatives

* **Stretch PostgreSQL before you reach for ES**
* Apache Solr (also built on Lucene)
* Sphinx
* RavenDB (MS)

---

# Let's use Elasticsearch!

The cat API provides access to basic information about an ES instance

To view the commans available:

`$ curl -XGET 'ekyqz8nza5:6gz15xze7h@elasticsearch-traini-2142321757.us-east-1.bonsaisearch.net/_cat'`

--

Let's try one:

`$ curl -XGET 'ekyqz8nza5:6gz15xze7h@elasticsearch-traini-2142321757.us-east-1.bonsaisearch.net/_cat/indices?v&pretty'`

---

# Elasticsearch, search

Conduct a search via the REST API

`$ curl -XGET 'ekyqz8nza5:6gz15xze7h@elasticsearch-traini-2142321757.us-east-1.bonsaisearch.net/book/_search?pretty' -H 'Content-Type: application/json' -d' { "query": { "match_all": {} } }'`

--

The response tells us:
* `hits` - search results info
* `hits.hits` - actual array of search results

Note that only 10 results are returned. We can customize the result set using the `from` and `size` parameters.

---

# Search Lingo

**Leaf query clauses** are individual conditions that can be joined into compound queries.

Leaf queries:
* Can be used by themselves

--

* Check for a value in a specified field

--

* Types: `term`, `range`, `type`, and more

---

# Search Lingo

**Compound query clauses** (aka full text queries) operate on the full text of a record.

Compound queries:
* Wrap leaf queries or other compound queries

--

* They can combine results or scores (e.g. dis_max, bool)

--

* They can alter the behavior of queries

--

* They can switch context

---

# Query Context  

The **context** in which a query clause is applied determines how it affects the result set.

A query clause used in **query context** answers the question "How well does this document match this query clause?"

* Includes a `_score` indicating how well the doc matches compared to other docs

--

* Can be fine-tuned for desired behavior using `boost`

--

* Query context is in effect whenever a query clause is passed to a query parameter, such as the query parameter in the search API

---

# Filter Context

A clause in a filter context answers the question "Does this document match this query clause?"

* Simple yes or no

--

* No scores

--

* Best for structured data like numeric or boolean fields

---

## Using Filter and Query Clauses

```nohighlight
$ curl -XGET 'localhost:9200/_search' -d'
{
  "query": { 
    "bool": { 
      "must": [
        { "match": { "title":   "Search"        }}, 
        { "match": { "content": "Elasticsearch" }}  
      ],
      "filter": [ 
        { "term":  { "status": "published" }}, 
        { "range": { "publish_date": { "gte": "2015-01-01" }}} 
      ]
    }
  }
}'
```

---

# Using Filter and Query Clauses

- Query and filter leaf clauses can be combined in one compound query
  - The "term" and "range" clauses use the filter context
  - They will remove non-matching results, but will not affect the `_score` for the matching results

---


# Full Text Queries

**Full text queries** are used to run searches on text fields like: email body, description of item

## Examples
`match`, `multi_match`, `common_terms`, `query_string`

--
They apply analyzers. (What's an analyzer?!)

---

# What's an Analyzer?

An analyzer:
* Break text content down into word stems (known as tokens or terms)
  * Those tokens are added to the inverted index
  * Words like "the" and "and" are skipped

--

* Can be customized for each text field in a mapping

--

* ES includes an English default

---

# Boosts & Highlighting

*  You can **boost** one field over another
  * For example, you might specify that location matters more than price range, so increase the score on location matches

--

* Matching snippets from fields in your search can be "highlighted" in the result set, allowing you to show users where the query matches are.

---

# Imprecise Queries

* Include the same data multiple times in different ways, or perform multiple, slightly different queries. This gets real complicated but is a common strategy, especially when you can load the data after the page loads

--

* The `more_like_this` query finds documents that are similar to your text or document(s)

--

* **Fuzzy Queries** allow you to match misspellings
  * Closeness to search term is calculated by edit distance. That is, the number of chars that would have to be deleted/added/changed

---

# Geo Queries

* There are several ways to calculate physical distance in searches

--

* Save latitude and longitude on the object (`geo_point` field)
  * Calculate precisely based on lat/long of a second point - `geo_distance` query
  * geo-bounding, faster - divide map into shaped areas (`geo_shape` field) and determine if your object is inside an area - `geo_bounding_box` or `geo_polygon` query

---

# Aggregations

* Aggregations allow you to group and provide statistics about your data

--

* ES can return hits and aggregated results in _one_ response

--

* Hits and aggregations are listed separately in the response:

`$ curl -XGET 'localhost:9200/bank/_search?pretty' -H 'Content-Type: application/json' -d' { "size": 0, "aggs": { "group_by_state": {"terms": {"field": "state.keyword"}}}}'`

--

This is similar in SQL: `SELECT state, COUNT(\*) FROM bank GROUP BY state ORDER BY COUNT(\*) DESC`

---

# Aggregations

* An aggregation is like a function that builds a result set over a group of documents
* You can get data like `min`, `max`, `avg`, `sum`, `range` things that are relatively easy to get out of SQL but are tough in a distributed environment

---

# Types of Aggregations

The different aggs can be divided into categories:
* Bucketing - divides documents into buckets
* Metric - track and make computations over a dataset
* Matrix - perform on multiple fields (limited implementation)
* Pipeline - aggs of other aggs and metrics. "meta-aggs"

---

# Geo Aggregations

* `geo_bounds`: computes a bounding box containing all geo points for a field (i.e. give me an area containing all the concert venues in this collection of businesses)
* `geo_centroid`: calculates the centroid/geometric center of a `geo_polygon`  (i.e. what's the centroid among a collection of restaurants serving ice cream?)
* `geo_distance`: User defines an origin point and a set of distance ranges, and it will return documents in those buckets of distance ranges. (i.e. what restaurants are within 10 miles of me? 25 miles?)

---

# Go Practice!

* In the walkthrough, you will practice making queries against a cluster
* Then in the studio, you will set up Elasticsearch on your own computer and experiment


</textarea>

<script type="text/javascript" src="../js/remark-latest.min.js"></script>
</body>
</html>
